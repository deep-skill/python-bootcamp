{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión lineal es una técnica de análisis de datos que predice el valor de datos desconocidos a partir del valor de datos conocidos y relacionados. Matemáticamente, la regresión lineal es una técnica estadística que relaciona una variable dependiente con una o más variables independientes.\n",
    "\n",
    "Planteemos el problema general de la regresión lineal. Dado un conjunto de valores $x, y: \\{(x_0, y_0), (x_1, y_1), \\cdots, (x_n, y_n)\\}$, donde $x_i$ e $y_i$ pueden ser valores multidimensionales, pero para este capítulo consideraremos que son valores de una sola dimensión. En un problema de regresión, estamos interesados en encontrar una función $f(x)$ que pasa sobre todos los puntos $(x_i, y_i)$, es decir\n",
    "\n",
    "$$\n",
    "y_i = f(x_i).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede parecer que este problema es muy complicado, pues existen infinitas funciones que pasen por cierto conjunto de puntos finitos. Sin embargo, reestructurando el problema un poco y asumiendo la forma general de $f()$ podemos resolver este complicado problema de regresión de una buena manera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reescribamos la función $f()$ en una función parametrizada y **reformulemos el problema de regresión en encontrar esos parámetros**\n",
    "\n",
    "$$\n",
    "y = f(x) = f(x;\\theta) = \\sum_{i=1}^m g_i(x;\\theta_i),\n",
    "$$\n",
    "\n",
    "donde $\\theta=(\\theta_1, \\cdots, \\theta_n)$ es un conjunto de parámetros que necesitamos encontrar para resolver el problema de regresión, y $g_1(), \\cdots, g_m()$ son nuestras funciones más simples donde sus parámetros son más sencillas de identificar comparadas a $f()$.\n",
    "\n",
    "Con esta definición parametrizada de $f()$, el problema de regresión se convierte en uno de optimización\n",
    "\n",
    "$$\n",
    "\\theta^* \\leftarrow \\arg\\min_{\\theta\\in\\mathbb{R}^d}\\sum_i(y_i-f(x_i;\\theta))^2,\n",
    "$$\n",
    "\n",
    "donde la sumatoria es para todos los puntos $\\{(x_1, y_1), \\cdots, (x_n, y_n)\\}$ que estamos intentando ajustar; $(y_i-f(x_i,\\theta))^2$ es el error entre el valor estimado $f(x_i;\\theta)$ y el valor correcto $y_i$ con $\\theta$ como parámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos describir la optimización entonces como: Encontrar los parámetros $\\theta$ que minimizen el error entre $y_i$ y lo que la función predice dado $x_i$ como entrada.\n",
    "\n",
    "Este es un problema de minimización:\n",
    "\n",
    "1. Regresión lineal, donde $f()$ se asume que será una línea, $y=ax+b$, y $\\theta$ es $(a, b)$\n",
    "2. Regresión no lineal, donde $f()$ tiene una naturaleza no lineal, por ejemplo, cuadrátrico, exponencial, logarítmico, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
